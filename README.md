# **Informe de agrupamiento usando K-Means & Python** 
#
#
## Introducci贸n:
El presente informe, creado por Miguel Esteban Parrado, tiene como objetivo mostrar y describir la soluci贸n a los requerimientos dados para el entregable AA2-EV01, correspondiente al curso ALGORITMO DE AGRUPAMIENTO NO SUPERVISADO K-MEANS CON PYTHON guiado por la instructora Diana Judith Mendez Torres.

En el presente informe, creado con el lenguaje de marcado ligero **Markdown**, se encontrar谩n las herramientas utilizadas para el desarrollo de susodicho entregable, como tambi茅n, el paso a paso para la soluci贸n de sus requerimientos.
#

### Herramientas utilizadas:

A continuaci贸n se mostrar谩n las herramientas con su respectiva versi贸n y/o documentaci贸n correspondiente para el desarrollo del entregable.

- Miniconda (25.3.1)
- Python (3.13.2)
- Librer铆as Python:

#

| Librer铆a | Documentaci贸n |
| ------ | ------ |
| Pandas | https://pandas.pydata.org/ |
| NumPy | https://numpy.org/ |
| Seaborn | https://seaborn.pydata.org/ |
| Matplotlib | https://matplotlib.org/ |
| Sklearn | https://scikit-learn.org/stable/ |
| Jupyter Notebook | https://docs.jupyter.org/en/latest/ |

![python](https://img.shields.io/badge/Python-%233776AB?style=flat-square&logo=python&logoColor=white)
#
## Objetivos 

- Cargar la base de datos a trabajar
- Obtener una muestra de prueba aleatoria a partir de la informaci贸n inicial.
- Eliminar las variables que no aportan al modelo
- Realizar el escalamiento (normalizaci贸n) de datos si es necesario.
- Obtener el valor 贸ptimo de K (cl煤sters) para la aplicaci贸n de algoritmo K-means.
- Entrenar el modelo, obtenci贸n de las coordenadas de los centroides.
- Realizar predicci贸n con la muestra obtenida.

#
#

### _Carga, limpieza de datos y configuraci贸n_

A trav茅s de la librer铆a [pandas](https://pandas.pydata.org/ ) realizamos una extracci贸n de la base de datos para la creaci贸n de un nuevo DataFrame y posteriormente, se eliminan las columnas no utilizadas. Adicionalmente, se realiza una configuraci贸n de la librer铆a matplotlib para la representaci贸n de gr谩ficos en Jupyter Notebook.

```sh
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib.pyplot as plt 
from sklearn.cluster import KMeans 
from sklearn.preprocessing import StandardScaler 

df = pd.read_csv("Mall_Customers1.csv")
df_numerico = df.drop(columns=["IDCliente", "Genero"])

%matplotlib inline 
sns.set(style="whitegrid") 
```

#
### _Muestra de prueba aleatoria_

Gracias al m茅todo **.sample()** podemos extraer una secuencia de ejemplos aleatoria para el DataFrame.

```sh
print("Muestar aleatoria de datos:")
muestra = df.sample(frac=0.2, random_state=42) 
print(muestra)  
```

#
### _Escalamiento o normalizaci贸n de datos_
Mediante la funci贸n **StandardScaler()** realizamos una normalizaci贸n o estandarizaci贸n de datos para que los datos de tipo num茅rico se aseguren de tener la misma importancia en el clustering.

```sh
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_numerico) 
```

#
### _Obtenci贸n y aplicaci贸n de valor 贸ptimo de cl煤sters_
A trav茅s del m茅todo del codo, el cual consiste en calcular la inercia y graficarla de tal manera que podamos visualizar la cantidad de cl煤sters ideales que necesitaremos para el algoritmo, nos fijaremos en el v茅rtice que simula el codo humano en la gr谩fica, para as铆, conocer el n煤mero 贸ptimo de cl煤sters y su implementaci贸n (aunque puede variar ese n煤mero "贸ptimo" de cl煤sters).

```sh
inertia = []
K_range = range(1, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k,random_state=42)
    kmeans.fit(df_scaled) 
    inertia.append(kmeans.inertia_)
```
Una vez creada la lista vac铆a para almacenar las incercias, mediante un ciclo **for**, vamos a almacenar la inercia en esta lista por cada modelo con n煤mero de cl煤sters desde el 1 al 10. Mostrando ahora una gr谩fica con este proceso o m茅todo del codo.

```sh
plt.figure(figsize=(8, 5))
plt.plot(K_range, inertia, marker='o', markerfacecolor='black', markeredgecolor='red')
plt.title('M茅todo del Codo para encontrar el K 贸ptimo')
plt.xlabel('N煤mero de Cl煤steres (K)')
plt.ylabel('Inercia')
plt.grid(True)
plt.show()
```
![M茅todo del codo](images/metodoCodo.png)

#
### _Entrenamiento del modelo_
Una vez los datos est茅n limpios, preparados y tengamos el n煤mero de cl煤sters 贸ptimo, procederemos a crear el algoritmo o modelo k-means, para as铆 entrenarlo, crear una nueva columna en el DataFrame llamada "Cl煤ster" y asignar a cada registro su n煤mero de cl煤ster correspondiente. 

```sh
print("Obtenci贸n de coordenadas por centroide:")
algoritmo = KMeans(n_clusters=4, random_state=42)
grupos = algoritmo.fit_predict(df_scaled)
df_numerico["Cluster"] = grupos

centroides_escalados = algoritmo.cluster_centers_
centroides = scaler.inverse_transform(centroides_escalados)
df_centroides = pd.DataFrame(centroides, columns=df_numerico.columns[:-1])  
df_centroides["Cluster"] = df_centroides.index
print(df_centroides)
```

#
### _Realizaci贸n de predicci贸n_
Finalmente, se muestra el gr谩fico de la predicci贸n realizada por el modelo:
#
![Gr谩fico de predicciones](images/prediccionesModelo.png)
#
En el cu谩l podemos concluir los siguientes 铆tems:

- El cl煤ster 1, refleja que las personas con una edad aproximada entre 25 a 35 a帽os, tienen una puntuaci贸n de gastos entre las mas altas, siendo de 60 a 100 puntos de gastos.
- El cl煤ster 0, refleja que, aproximadamente las personas con menor cantidad de ingresos, son las personas con edades entre los 40 a 70 a帽os
- El cl煤ster 3, refleja que, aproximadamente, las personas con ingresos entre 70 a 140 puntos, son las personas que menos gastan, entre 0 a 45 puntos
- El cl煤ster 0 y 2, muestran una gran relaci贸n o agrupamiento de datos entre ciertos puntos de gastos e ingresos, siendo las personas con ingresos entre 45 a 55 puntos las que gastan entre 40 a 70 puntos.

#
#

### Referencias:
- Instructora: Diana Mendez 
#

_Gracias por leer..._

#
#
>"Incluso cuando te tomas unas vacaciones de la tecnolog铆a, 
>la tecnolog铆a no se toma un descanso de ti"
>-Douglas Coupland
